{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCks7pCW56yn",
        "outputId": "d698b968-8efe-4f37-8fe0-ac5aa41ce620"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        }
      ],
      "source": [
        "# Install the required libraries\n",
        "pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7PmPxA16DMt",
        "outputId": "a80b5d32-c4e6-4b89-f411-c7cdd4f96063"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "import random\n",
        "import pandas as pd\n",
        "import tqdm"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3Nh3d_4H6DDz"
      },
      "source": [
        "Create the direct relations dataset. Here we will "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQUviYj-6CyD",
        "outputId": "7291810d-6736-400f-c3cc-d36b07779a2d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Progress: 100%|██████████| 117659/117659 [00:47<00:00, 2501.97it/s]\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "import random\n",
        "import pandas as pd\n",
        "import tqdm\n",
        "\n",
        "\n",
        "# Obter todas as synsets em WordNet\n",
        "all_synsets = list(wn.all_synsets())\n",
        "\n",
        "num_iterations = len(all_synsets)\n",
        "# Criar uma lista para armazenar os dataframes\n",
        "dataframes = []\n",
        "\n",
        "\n",
        "# Iniciar a iteração\n",
        "for iteration in tqdm.tqdm(range(num_iterations), desc='Progress'):\n",
        "\n",
        "    # Obter uma synset aleatória\n",
        "    synset = all_synsets[iteration]\n",
        "\n",
        "    hypernyms = synset.hypernyms()\n",
        "    hypernyms_data = {\n",
        "        'Definição_Synset': [synset.definition() for _ in range(len(hypernyms))],\n",
        "        'ID_Synset': [synset.name() for _ in range(len(hypernyms))],\n",
        "        'Definição_Relacionada': [h.definition() for h in hypernyms],\n",
        "        'ID_Relacionada': [h.name() for h in hypernyms],\n",
        "        'Relacao': ['Hypernyms' for _ in range(len(hypernyms))]\n",
        "    }\n",
        "    hypernyms_df = pd.DataFrame(hypernyms_data)\n",
        "    dataframes.append(hypernyms_df)\n",
        "\n",
        "    #append de holonym data\n",
        "    holonyms = synset.part_holonyms() + synset.substance_holonyms() + synset.member_holonyms()\n",
        "    holonyms_data = {\n",
        "        'Definição_Synset': [synset.definition() for _ in range(len(holonyms))],\n",
        "        'ID_Synset': [synset.name() for _ in range(len(holonyms))],\n",
        "        'Definição_Relacionada': [h.definition() for h in holonyms],\n",
        "        'ID_Relacionada': [h.name() for h in holonyms],\n",
        "        'Relacao': ['Holonyms' for _ in range(len(holonyms))]\n",
        "    }\n",
        "    holonyms_df = pd.DataFrame(holonyms_data)\n",
        "    dataframes.append(holonyms_df)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "combined_df = pd.concat(dataframes)\n",
        "\n",
        "# Remove any occasional duplicate records\n",
        "df_no_duplicates = combined_df.drop_duplicates()\n",
        "\n",
        "df_no_duplicates.to_csv('direct_relations.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNvnXPqFX-7y",
        "outputId": "c2383ceb-efb8-4687-eb0c-448caa6d6f69"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Hypernyms    88529\n",
              "Holonyms     22146\n",
              "Name: Relacao, dtype: int64"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class_counts = df_no_duplicates['Relacao'].value_counts()\n",
        "class_counts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a4yRsXi_kOH"
      },
      "source": [
        "Indirect dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMqjiARyEVaR"
      },
      "outputs": [],
      "source": [
        "all_synsets = list(wn.all_synsets())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MGX79tV2ZwQ8",
        "outputId": "84a7e8ef-a503-4c5e-90fe-bfa1db7f3976"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Progress:  55%|█████▌    | 65073/117659 [29:53<2:24:09,  6.08it/s]"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "def build_hypernym_matrix():\n",
        "    synsets = list(wn.all_synsets())\n",
        "    num_synsets = len(synsets)\n",
        "    hypernym_matrix = np.zeros((num_synsets, num_synsets), dtype=int)\n",
        "\n",
        "    def add_hypernyms(synset, hypernym_indices):\n",
        "        for hypernym in synset.hypernyms():\n",
        "            hypernym_index = synsets.index(hypernym)\n",
        "            hypernym_indices.add(hypernym_index)\n",
        "            add_hypernyms(hypernym, hypernym_indices)\n",
        "\n",
        "    for i, synset in enumerate(synsets):\n",
        "        print(f\"Processing synset {i + 1} of {num_synsets}...\")\n",
        "        hypernym_indices = set()\n",
        "        add_hypernyms(synset, hypernym_indices)\n",
        "        for j in hypernym_indices:\n",
        "            hypernym_matrix[i, j] = 1\n",
        "\n",
        "    return hypernym_matrix\n",
        "\n",
        "hypernym_matrix = build_hypernym_matrix()\n",
        "print(hypernym_matrix)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
